# This work was done during a research project in the Scientific Research Seminar "Methods of Data Mining and Computational Linguistics"
## Student - Rafikov A.S.
## Curator - Krylov V.V.


### This work evaluates the frequency of hallucinations in LLMs, working with context and correctly specifying sources to confirm their statements on various topics, for example, chess, the solar system, love relationships and others. The problems of most models in matching the response to the request, as well as understanding the minimum requested information, are also clearly highlighted.


### The results of the work are presented in the form of an article and data files


### Referenced by article Trapping LLM “Hallucinations” Using Tagged Context Prompts 
### authors: Philip Feldman, James R. Foulds, and Shimei Pan
